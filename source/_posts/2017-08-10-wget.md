---
title: wget
tags:
  - wget
categories:
  - 命令行工具
date: 2017-08-10 17:37:33
---


用于文件下载的命令行工具，特点在于 **批量下载(batch files)** 和 **后台任务(cron jobs)**。

## 对比 `curl`

|wegt|curl|
|--|--|
|纯粹的命令行工具|由 `libcurl` 库支持|
|支持的协议有限 `http` `https` `ftp` |支持更多协议|
|仅支持 `http 1.0` |默认支持 `http 1.1` |
|支持递归下载，并行下载|批量下载要求 url 有特定模式|
|后台自动下载|不支持|

> `wget`支持**自动下载**，就是说你启动wget任务后用户可以登出系统，`wget`**将在后台执行**直到任务完成。

总而言之，仅仅是下载文件，`wget` 是更好的选择。

## 常用选项

```
wget -b -c --tries=NUMBER URL
```

|选项|作用|
|--|--|
|`-h`|帮助|
|`-b`|后台执行|
|`-c`|断点续传，需要服务器支持|
|`-t` `--tries`|重试次数<br>`-t 3` 重试3次<br>`-t 0` 不停重试|
|`-O` `--output-file=FILE`|指定输出文件|
|`-o`|用于写入日志|
|`--limit-rate`|下载限速`--limit-rate 20k`<br>`--limit-rate 20m`|
|`-Q` `--quota`|限制下载总量`-Q 100m`|
|`-m` `--mirror`|制作镜像站点|
|`-w 5` `--await=5`|请求间等待的时间，默认单位为秒|
|`--accept jpg`|指定下载特定的文件后缀|
|`--reject jpg`|不下载的文件|
|`-k` `--convert-links`|将页面的连接地址转为本地地址|
|`--level 0`|0 表示不限制递归层级|
|`--user` `--passworld` `--ask-password`|密码和认证`--user foo --password bar`|
|`-U` `--user-agent=AGENT`|指定 UA|
|`-r`|递归下载|
|`-x`|强制建立服务器上一模一样的目录|
|`-i`|批量下载，需要把url写到文件中，每个url写一行|
|`-V`|显示版本|
|`-a` <br>`--append-output FILE`|把记录追加到FILE|
|`-q`|安静模式|
|`-v`|冗长模式|
|`--spider`|不下载任何文件|
|`-e robots=off`|e执行命令|

## 示例

```bash
wget URL
wget URL1 URL2 # 指定多个url下载
wget -i WGET_DOWNLOADS.txt # 通过文件批量下载
wget -r -N -l -k DEPTH http://www.foo.com
wget --mirror --convert-links foo.com
wget --spider -o wget.log -e robots=off --wait 1 -r -p http://luhaozhao.com # 生成一个日志文件检测出坏链接
```

